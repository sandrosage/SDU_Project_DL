{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "\n",
    "\n",
    "def train_test_val_split(size, train_split, test_split, src_dir):\n",
    "    category = [\"normal\", \"pneumonia\"]\n",
    "    split_list = [\"train\", \"test\", \"val\"]\n",
    "    for split in split_list:\n",
    "        if not os.path.exists(\"Project_Day\\\\\" + split + \"\\\\\" ): \n",
    "            os.mkdir(\"Project_Day\\\\\" + split + \"\\\\\")\n",
    "        for cat in category:\n",
    "            if not os.path.exists(\"Project_Day\\\\\" + split + \"\\\\\" + cat + \"\\\\\"): \n",
    "                os.mkdir(\"Project_Day\\\\\" + split + \"\\\\\" + cat + \"\\\\\")\n",
    "   \n",
    "    index = 1\n",
    "    \n",
    "    for jpgfile in glob.iglob(os.path.join(src_dir, \"*.jpg\")):\n",
    "        if (index<=(size*train_split)):\n",
    "            if \"normal\" in jpgfile:\n",
    "                shutil.copy(jpgfile, \"Project_Day\\\\\" + \"train\\\\\" + \"normal\\\\\")\n",
    "\n",
    "            else:\n",
    "                shutil.copy(jpgfile, \"Project_Day\\\\\" + \"train\\\\\" + \"pneumonia\\\\\")\n",
    "\n",
    "            index+=1\n",
    "\n",
    "        elif ((size*train_split)<index<=((size*train_split)+ (size*test_split))):\n",
    "            if \"normal\" in jpgfile:\n",
    "                shutil.copy(jpgfile, \"Project_Day\\\\\" + \"test\\\\\" + \"normal\\\\\")\n",
    "\n",
    "            else:\n",
    "                shutil.copy(jpgfile, \"Project_Day\\\\\" + \"test\\\\\" + \"pneumonia\\\\\")\n",
    "\n",
    "            index+=1\n",
    "        \n",
    "        else:\n",
    "            if \"normal\" in jpgfile:\n",
    "                shutil.copy(jpgfile, \"Project_Day\\\\\" + \"val\\\\\" + \"normal\\\\\")\n",
    "\n",
    "            else:\n",
    "                shutil.copy(jpgfile, \"Project_Day\\\\\" + \"val\\\\\" + \"pneumonia\\\\\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_val_split(2200, 0.8, 0.1, \"Project_Day\\\\data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110\n"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "for file in os.listdir(\"Project_Day\\\\val\\\\pneumonia\"):\n",
    "    index+=1\n",
    "print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1760 images belonging to 2 classes.\n",
      "Found 220 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'Project_Day/train',\n",
    "        target_size=(256, 256),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')\n",
    "        \n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        'Project_Day/val',\n",
    "        target_size=(256, 256),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n",
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_layer (InputLayer)    [(None, 256, 256, 3)]     0         \n",
      "                                                                 \n",
      " conv2d_15 (Conv2D)          (None, 252, 252, 64)      4864      \n",
      "                                                                 \n",
      " conv2d_16 (Conv2D)          (None, 250, 250, 32)      18464     \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 249, 249, 32)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_17 (Conv2D)          (None, 247, 247, 32)      9248      \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 1952288)           0         \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 1952288)           0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 64)                124946496 \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 124,983,362\n",
      "Trainable params: 124,983,362\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import pool\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras import Input\n",
    "from keras.utils.vis_utils import plot_model\n",
    "import visualkeras \n",
    "\n",
    "input_layer = Input(shape=(256,256,3), name='input_layer')\n",
    "conv_1 = Conv2D(64, kernel_size=(5,5))(input_layer)\n",
    "conv_2 = Conv2D(32,kernel_size=(3,3))(conv_1)\n",
    "pool_1 = MaxPooling2D(pool_size=(2,2), strides=(1,1))(conv_2)\n",
    "conv_3 = Conv2D(32, kernel_size=(3,3))(pool_1)\n",
    "flatten = Flatten()(conv_3)\n",
    "dropout = Dropout(0.3)(flatten)\n",
    "dense_1 = Dense(64, activation=\"relu\")(dropout)\n",
    "dense_2 = Dense(64, activation=\"relu\")(dense_1)\n",
    "output_layer = Dense(2, activation=\"sigmoid\")(dense_2)\n",
    "model = Model(input_layer, output_layer)\n",
    "\n",
    "dot_img_file = 'model_2.png'\n",
    "plot_model(model, to_file=dot_img_file, show_shapes=True)\n",
    "model.summary()\n",
    "#visualkeras.layered_view(model) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Could not import PIL.Image. The use of `load_img` requires PIL.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\sandr\\source\\repos\\SDU_Project_DL\\SDU_Project_DL\\directory_order.ipynb Zelle 6\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/sandr/source/repos/SDU_Project_DL/SDU_Project_DL/directory_order.ipynb#X13sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m steps_per_epochs\u001b[39m=\u001b[39m\u001b[39m2000\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/sandr/source/repos/SDU_Project_DL/SDU_Project_DL/directory_order.ipynb#X13sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(loss\u001b[39m=\u001b[39mBinaryCrossentropy(), optimizer\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39madam\u001b[39m\u001b[39m\"\u001b[39m, metrics\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/sandr/source/repos/SDU_Project_DL/SDU_Project_DL/directory_order.ipynb#X13sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(train_generator, steps_per_epoch\u001b[39m=\u001b[39;49msteps_per_epochs, epochs\u001b[39m=\u001b[39;49mepochs, validation_data\u001b[39m=\u001b[39;49mvalidation_generator, validation_steps\u001b[39m=\u001b[39;49m\u001b[39m800\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\sandr\\source\\repos\\SDU_Project_DL\\SDU_Project_DL\\venva\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\sandr\\source\\repos\\SDU_Project_DL\\SDU_Project_DL\\venva\\lib\\site-packages\\keras\\utils\\image_utils.py:386\u001b[0m, in \u001b[0;36mload_img\u001b[1;34m(path, grayscale, color_mode, target_size, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[0;32m    384\u001b[0m   color_mode \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mgrayscale\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    385\u001b[0m \u001b[39mif\u001b[39;00m pil_image \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 386\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mCould not import PIL.Image. \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    387\u001b[0m                     \u001b[39m'\u001b[39m\u001b[39mThe use of `load_img` requires PIL.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    388\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(path, io\u001b[39m.\u001b[39mBytesIO):\n\u001b[0;32m    389\u001b[0m   img \u001b[39m=\u001b[39m pil_image\u001b[39m.\u001b[39mopen(path)\n",
      "\u001b[1;31mImportError\u001b[0m: Could not import PIL.Image. The use of `load_img` requires PIL."
     ]
    }
   ],
   "source": [
    "from keras.losses import BinaryCrossentropy\n",
    "batch_size = 32\n",
    "epochs = 15\n",
    "steps_per_epochs=2000\n",
    "\n",
    "model.compile(loss=BinaryCrossentropy(), optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "history = model.fit(train_generator, steps_per_epoch=steps_per_epochs, epochs=epochs, validation_data=validation_generator, validation_steps=800)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('venva': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7bd0aadbca86c4df0ac1b3c0b1205895a23818683820ce4de8c809debd574e98"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
